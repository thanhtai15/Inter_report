---
title: "Worklog Tuần 9"
date: "2025-11-05"
weight: 9
chapter: false
pre: " <b> 1.9. </b> "
---



### Mục tiêu tuần 9:

* Học AWS Bedrock và áp dụng vào dự án:
  * Tìm hiểu Bedrock architecture và các Foundation Models
  * Nghiên cứu các mô hình: Claude, Llama, Titan, Jurassic
  * Học cách tạo prompts hiệu quả (prompt engineering)
  * Tích hợp Bedrock API vào ứng dụng
  * So sánh Bedrock với các giải pháp AI khác
* Nghiên cứu kiến thức NLP cần thiết - Deep Learning cho NLP:
  * Transformer architecture chi tiết (Attention is All You Need)
  * So sánh Transformers vs RNNs/LSTMs
  * Scaled Dot-Product Attention và Multi-Head Attention
  * Masked Self-Attention trong Decoder
  * Positional Encoding và tầm quan trọng
  * Các mô hình nổi tiếng: BERT, GPT, T5, ELMo
* Thực hành LeetCode để nâng cao kỹ năng lập trình:
  * Giải các bài toán về String manipulation
  * Thuật toán Dynamic Programming
  * Data structures: Arrays, Hash Tables, Trees
  * Cải thiện problem-solving và coding speed

### Các công việc cần triển khai trong tuần này:
| Thứ | Công việc                                                                                                                                                                                   | Ngày bắt đầu | Ngày hoàn thành | Nguồn tài liệu                            |
| --- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | --------------- | ----------------------------------------- |
| 2   | - Tìm hiểu về Transformers vs RNNs <br> - Tìm hiểu về Scaled and Dot-Product Attention <br> - Tìm hiểu về Masked Self Attention <br> - Tìm hiểu về Transformer Decoder                                                                                            | 03/11/2025   | 03/11/2025      | <https://www.coursera.org/learn/attention-models-in-nlp/>
| 3   | - Làm lab code thực hành về Transformer Summarizer <br> - Tối ưu lại ChatBot và giao diện| 04/011/2025   | 04/11/2025      | https://www.coursera.org/learn/attention-models-in-nlp/> |
| 4   | - Meeting thay đổi 1 số dịch vụ AWS tối ưu lại dự án <br> - Tìm hiểu Transfer Learning in NLP <br> - Tìm hiểu về các mô hình ngôn ngữ lớn ELMo, GPT, BERT, T5 | 05/11/2025   | 05/11/2025      | <https://www.coursera.org/learn/attention-models-in-nlp/> |
| 5   | - Tìm hiểu về AWS Bedrock <br> - Thử nghiệm tại AI Chatbot với AWS Bedrock | 06/11/2025   | 06/11/2025      |  |
| 6   | - Tìm kiếm và tạo dữ liệu cho Chatbot tạo bằng AWS Bedrock <br> - Kiểm thử ChatBot và sửa 1 vài lỗi liên quan đến quá trình làm                                                                                         | 07/11/2025   | 07/11/2025      |  |


### Kết quả đạt được tuần 9:

* Tìm hiểu về Transformer và các mô hình NLP:
  * Hiểu kiến trúc và cơ chế hoạt động của Transformer
  * Học về cấu trúc Encoder-Decoder, Attention Mechanism
  * Tìm hiểu các mô hình nổi bật: BERT, GPT
  * Áp dụng kiến thức Transformer vào bài toán xử lý ngôn ngữ tự nhiên

* Nghiên cứu và học về AWS Bedrock:
  * Hiểu các khái niệm và tính năng chính của Bedrock
  * Học cách sử dụng AWS Bedrock để tích hợp Large Language Models (LLMs)
  * Nghiên cứu các mô hình pre-trained phổ biến trên nền tảng Bedrock
  * Khám phá use cases thực tế trong dự án

* Thực hành thuật toán:
  * Hoàn thành các bài tập LeetCode để nâng cao kỹ năng giải thuật
  * Cải thiện tư duy tối ưu code và thuật toán

* Chuẩn bị cho dự án:
  * Lên kế hoạch áp dụng Bedrock vào dự án cuối kỳ
  * Xem xét lại kiến trúc để tích hợp các mô hình AI
  * Chuẩn bị nền tảng kiến thức cho việc triển khai trong các tuần tiếp theo


